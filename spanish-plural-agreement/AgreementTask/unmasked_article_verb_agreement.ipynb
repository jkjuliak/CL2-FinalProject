{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d40805",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "### Basic logistical, wrangling, & visualization imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "### Model imports\n",
    "from transformers import BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e8fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define useful functions\n",
    "\n",
    "def make_sentences_df(dct_noun,df_noun):\n",
    "    \"\"\"Creates sentence templates masking what should be a definite plural or singular article\n",
    "    INPUTS: dct_noun: dictionary, noun:article pairs, the article is lowercase, singular, and gendered--this \n",
    "                      was hand-annotated from native Caribbean Spanish speaker intuition and checks in online\n",
    "                      dictionary of the Real Academia Espa√±ola; if there are any concerns about gendered article \n",
    "                      errors, check here first\n",
    "            df_noun: pandas dataframe, cols: whole_word (plural), root (becomes our lemma), affix (s or es)--\n",
    "                     this df is drawn from a noun subset of AnCora Tree Bank\"\"\"\n",
    "    \n",
    "    gather_df = []\n",
    "    for noun in tqdm(dct_noun.keys()): \n",
    "        \n",
    "        subdf = df_noun[df_noun['whole_word'] == noun]\n",
    "\n",
    "        ### set up singular & plural template components\n",
    "        sing_art = dct_noun[noun]\n",
    "        sing_art = str(sing_art[0].upper() + sing_art[1])\n",
    "\n",
    "        sing_subj = subdf['root'].values[0]\n",
    "\n",
    "        plur_subj = noun\n",
    "\n",
    "        ### set up target definite articles\n",
    "        if sing_art == 'El':\n",
    "\n",
    "            plur_art= 'Los'\n",
    "\n",
    "\n",
    "        elif sing_art == 'La': \n",
    "\n",
    "            plur_art = 'Las'\n",
    "\n",
    "        ### set up target singluar and plural verbs\n",
    "\n",
    "        sing_verb = \"es\"\n",
    "\n",
    "        plur_verb = \"son\"\n",
    "\n",
    "        ### set up composite template components\n",
    "        affix = subdf['affix'].values[0]\n",
    "        comp_subj = sing_subj +'##'+ affix\n",
    "\n",
    "\n",
    "        ### create all sentence templates\n",
    "\n",
    "        sing_sentence_template = sing_art + ' ' + sing_subj + ' [MASK]'\n",
    "\n",
    "        plur_sentence_template = plur_art + ' ' + plur_subj + ' [MASK]'\n",
    "\n",
    "        comp_sentence_template = plur_art + ' ' + comp_subj + ' [MASK]'\n",
    "\n",
    "        ### set up all the column/row entries you will store per lemma\n",
    "\n",
    "        all_wordforms = [sing_subj,\n",
    "                         plur_subj,\n",
    "                         comp_subj]\n",
    "\n",
    "        all_word_number = ['sing',\n",
    "                           'plur',\n",
    "                           'plur'] \n",
    "\n",
    "        all_n_tokens = [len(tokenizer.encode(sing_subj,add_special_tokens=False)),\n",
    "                        len(tokenizer.encode(plur_subj,add_special_tokens=False)),\n",
    "                        len(tokenizer.encode(sing_subj,add_special_tokens=False)) + len(tokenizer.encode(['##'+affix],add_special_tokens=False))                           ]\n",
    "\n",
    "        all_sentence_templates = [sing_sentence_template,\n",
    "                                  plur_sentence_template,\n",
    "                                  comp_sentence_template]\n",
    "            \n",
    "        #this is a super important column! distinguishes the default tokenization from \n",
    "        #our artificially imposed tokenization scheme\n",
    "        all_tokenization_types = ['default',\n",
    "                                  'default',\n",
    "                                  'artificial']\n",
    "\n",
    "        d = {'lemma': np.repeat(sing_subj,len(all_sentence_templates)),\n",
    "             'word_form': all_wordforms,\n",
    "             'word_number': all_word_number,\n",
    "             'n_tokens': all_n_tokens,\n",
    "             'tokenization_type': all_tokenization_types,\n",
    "             'sentence': all_sentence_templates,\n",
    "             'target_ART_sing': sing_art, \n",
    "             'target_ART_plur': plur_art,\n",
    "             'target_VERB_sing': sing_verb,\n",
    "             'target_VERB_plur': plur_verb,\n",
    "             'affix': np.repeat(affix,len(all_sentence_templates))\n",
    "             }\n",
    "\n",
    "        gather_df.append(pd.DataFrame(d))\n",
    "\n",
    "    sentence_df = pd.concat(gather_df,ignore_index=True)\n",
    "    return sentence_df\n",
    "\n",
    "\n",
    "### Model Predictions \n",
    "\n",
    "def find_sublist_index(list, sublist):\n",
    "    \"\"\"Find the first occurence of sublist in list.\n",
    "    Return the start and end indices of sublist in list.\n",
    "    Used to find index of [MASK] in template sentences.\n",
    "\n",
    "    h/t GPT-3-codex for writing this.\"\"\"\n",
    "\n",
    "    for i in range(len(list)):\n",
    "        if list[i] == sublist[0] and list[i:i+len(sublist)] == sublist:\n",
    "            return i, i+len(sublist)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_article_predictions(df,data_source): \n",
    "    \"\"\"Predict the likelihood of target definite/indefinite and singular/plural articles\n",
    "       Will assume you've already loaded and defined your tokenizer and model.\n",
    "       Will iterate row by row in your dataframe `df`, containing cols for masked sentences,\n",
    "       the corresponding lemma and plural forms being tested. When it comes across a row\n",
    "       with column `tokenizer_type` label `artificial`, will shunt you to a process that creates\n",
    "       the inputs to the model by hand (if there are any issues/concerns with how the artificial\n",
    "       tokenization proceeds and leads to predictions, check the following `if` statement: \n",
    "       `if row['tokenization_type'] == 'artificial'`)\n",
    "       \n",
    "       INPUTS: df, pandas dataframe, cols for lemma, word_number (plural, singular), tokenization_type\n",
    "                   (artificial/default), masked sentence, target singular and plural articles to \n",
    "                   get probabilities for filling in the [MASK], and others\"\"\"\n",
    "\n",
    "    gather_df = []\n",
    "    gather_debug = []\n",
    "    for (_,row) in tqdm(df.iterrows(),total=df.shape[0]):\n",
    "\n",
    "        if row['word_number'] == 'sing':\n",
    "            target_article = row['target_ART_sing']\n",
    "        else:\n",
    "            target_article = row['target_ART_plur']\n",
    "\n",
    "\n",
    "        #tokens for each article type \n",
    "        token_article= tokenizer.encode(target_article,\n",
    "                                              add_special_tokens=False\n",
    "                                         )\n",
    "\n",
    "                                    \n",
    "        #token for mask\n",
    "        token_mask = tokenizer.encode('[MASK]',\n",
    "                                      add_special_tokens=False\n",
    "                                     )\n",
    "\n",
    "        target_verb_sing = row['target_VERB_sing']\n",
    "        target_verb_plur = row['target_VERB_plur']\n",
    "\n",
    "        #tokens for each verb number \n",
    "        token_verb_sing = tokenizer.encode(target_verb_sing,\n",
    "                                              add_special_tokens=False\n",
    "                                         )\n",
    "        token_verb_plur = tokenizer.encode(target_verb_plur,\n",
    "                                              add_special_tokens=False\n",
    "                                         )\n",
    "\n",
    "        ### Set up your representation of the sentence for the \n",
    "        #.  model\n",
    "\n",
    "        if row['tokenization_type'] == 'artificial': \n",
    "\n",
    "            if '##es' in row['word_form']:\n",
    "\n",
    "                token_affix = tokenizer.convert_tokens_to_ids([\"##es\"])\n",
    "\n",
    "\n",
    "            elif '##s' in row['word_form']: \n",
    "\n",
    "                token_affix = tokenizer.convert_tokens_to_ids([\"##s\"])\n",
    "\n",
    "            #token for singular form\n",
    "            lemma = row['lemma']\n",
    "            token_lemma = tokenizer.encode(lemma,\n",
    "                                           add_special_tokens=False\n",
    "                                          )\n",
    "            print(token_lemma)\n",
    "            #TODO: Check for source and if it's non-morphemic, combine the tokens that the lemma gets broken into\n",
    " \n",
    "            #token for special start\n",
    "            start = '[CLS]'\n",
    "            token_start = tokenizer.encode(start,\n",
    "                                           add_special_tokens=False)\n",
    "            \n",
    "\n",
    "            #token for special end\n",
    "            ending = '[SEP]'\n",
    "            token_end = tokenizer.encode(ending,\n",
    "                                         add_special_tokens=False)\n",
    "            \n",
    "            \n",
    "            ### Collect your tokens into a list that you will then flatten\n",
    "            #   prior to converting to tensor\n",
    "            bulky_token_list = [token_start,\n",
    "                                token_article,\n",
    "                                token_lemma,\n",
    "                                token_affix,\n",
    "                                token_mask,\n",
    "                                token_end\n",
    "                                ]\n",
    "            flat_token_list = [item for sublist in bulky_token_list for item in sublist]\n",
    "            token_idx = torch.tensor([flat_token_list])\n",
    "            \n",
    "\n",
    "            inputs = {'input_ids': token_idx,\n",
    "                      'token_type_ids': torch.zeros_like(token_idx),\n",
    "                      'attention_mask': torch.ones_like(token_idx)\n",
    "                     }\n",
    "\n",
    "        elif row['tokenization_type']=='default': \n",
    "\n",
    "            inputs = tokenizer(row['sentence'],\n",
    "                               return_tensors='pt',\n",
    "                               add_special_tokens=True\n",
    "                              )\n",
    "            \n",
    "        model_token_inputs = tokenizer.convert_ids_to_tokens(inputs['input_ids'].tolist()[0])\n",
    "        model_token_inputs = ' , '.join(model_token_inputs)\n",
    "\n",
    "        ### Predict the item that should fill in the mask!\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        #find the index of the mask in sentence\n",
    "        midx = find_sublist_index(inputs[\"input_ids\"][0].tolist(),\n",
    "                                  token_mask)\n",
    "                                 \n",
    "        masked_token_logits = outputs.logits[0][midx[0]]\n",
    "        masked_token_probs = torch.softmax(masked_token_logits, dim=0)\n",
    "\n",
    "\n",
    "        # prob_article_sing = masked_token_probs[token_article_sing].item()\n",
    "        # prob_article_plur = masked_token_probs[token_article_plur].item()\n",
    "\n",
    "        # prob_list = [prob_article_sing, prob_article_plur]\n",
    "        # article_list = [target_article_sing, target_article_plur]\n",
    "    \n",
    "\n",
    "        prob_verb_sing = masked_token_probs[token_verb_sing].item()\n",
    "        prob_verb_plur = masked_token_probs[token_verb_plur].item()\n",
    "\n",
    "        prob_list = [prob_verb_sing, prob_verb_plur]\n",
    "        verb_list = [target_verb_sing, target_verb_plur]\n",
    "\n",
    "    \n",
    "        ### Store your results\n",
    "\n",
    "        d = {'lemma': np.repeat(row['lemma'],len(prob_list)),\n",
    "             'word_form': np.repeat(row['word_form'],len(prob_list)),\n",
    "             'word_number': np.repeat(row['word_number'],len(prob_list)),\n",
    "             'n_tokens': np.repeat(row['n_tokens'],len(prob_list)),\n",
    "             'tokenization_type': np.repeat(row['tokenization_type'],len(prob_list)),\n",
    "             'verb_probs': prob_list,\n",
    "             'article_number': ['singular','plural'],\n",
    "             'verb_number': ['singular','plural'],\n",
    "             'verb': verb_list,\n",
    "             'affix': row['affix'],\n",
    "             'sentence': row['sentence'],\n",
    "             'model_token_inputs': model_token_inputs,\n",
    "             'source': data_source\n",
    "            }\n",
    "        gather_df.append(pd.DataFrame(d))\n",
    "\n",
    "\n",
    "        debug_d = {'lemma': [row['lemma']],\n",
    "                   'word_form': [row['word_form']],\n",
    "                   'tokenized_sentence': [inputs[\"input_ids\"][0].tolist()],\n",
    "                   'mask_index': [midx[0]]\n",
    "                  }\n",
    "        gather_debug.append(pd.DataFrame(debug_d))\n",
    "\n",
    "\n",
    "    probs_df = pd.concat(gather_df,ignore_index=True)\n",
    "    debug_df = pd.concat(gather_debug,ignore_index=True)\n",
    "    \n",
    "    return probs_df,debug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c976112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=31002, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Import the necessary\n",
    "\n",
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "### Create the tokenizer and the model\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff1d5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8513a8b4287044ff841fe605ae30896a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original list len: 1363 select list len: 1247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7827506a3b5f45f6a02c19c5909370af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3741 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5850]\n",
      "[14089]\n",
      "[7388]\n",
      "[5911]\n",
      "[9823]\n",
      "[3785]\n",
      "[2378]\n",
      "[13651]\n",
      "[17022]\n",
      "[1944]\n",
      "[14878]\n",
      "[4772]\n",
      "[7746]\n",
      "[2274]\n",
      "[5411]\n",
      "[3921]\n",
      "[2784]\n",
      "[2957]\n",
      "[7043]\n",
      "[2395]\n",
      "[5721]\n",
      "[2966]\n",
      "[1814]\n",
      "[3325]\n",
      "[4443]\n",
      "[2116]\n",
      "[12032]\n",
      "[4149]\n",
      "[3455]\n",
      "[2209]\n",
      "[11381]\n",
      "[12653]\n",
      "[5444]\n",
      "[7473]\n",
      "[1890]\n",
      "[6560]\n",
      "[8222]\n",
      "[7076]\n",
      "[5186]\n",
      "[4627]\n",
      "[8316]\n",
      "[4598]\n",
      "[4379]\n",
      "[27438]\n",
      "[15018]\n",
      "[6013]\n",
      "[2709]\n",
      "[4244]\n",
      "[2307]\n",
      "[5651]\n",
      "[12500]\n",
      "[3179]\n",
      "[14955]\n",
      "[2981]\n",
      "[22553]\n",
      "[11623]\n",
      "[9200]\n",
      "[5070]\n",
      "[4840]\n",
      "[1730]\n",
      "[6835]\n",
      "[1560]\n",
      "[7172]\n",
      "[3434]\n",
      "[9454]\n",
      "[9342]\n",
      "[6114]\n",
      "[4660]\n",
      "[11171]\n",
      "[15643]\n",
      "[3305]\n",
      "[1708]\n",
      "[8955]\n",
      "[3219]\n",
      "[7984]\n",
      "[4436]\n",
      "[5705]\n",
      "[3918]\n",
      "[3630]\n",
      "[2353]\n",
      "[6067]\n",
      "[9866]\n",
      "[2483]\n",
      "[7958]\n",
      "[5029]\n",
      "[4792]\n",
      "[12078]\n",
      "[6289]\n",
      "[5529]\n",
      "[24137]\n",
      "[2153]\n",
      "[3038]\n",
      "[10884]\n",
      "[12112]\n",
      "[9574]\n",
      "[3531]\n",
      "[4196]\n",
      "[10508]\n",
      "[11554]\n",
      "[2984]\n",
      "[15951]\n",
      "[2743]\n",
      "[5076]\n",
      "[6599]\n",
      "[14627]\n",
      "[3889]\n",
      "[2444]\n",
      "[18803]\n",
      "[4198]\n",
      "[4837]\n",
      "[6876]\n",
      "[12175]\n",
      "[3599]\n",
      "[3428]\n",
      "[1726]\n",
      "[27125]\n",
      "[9291]\n",
      "[6290]\n",
      "[3661]\n",
      "[5161]\n",
      "[12049]\n",
      "[9738]\n",
      "[4137]\n",
      "[7412]\n",
      "[11551]\n",
      "[15817]\n",
      "[17802]\n",
      "[2785]\n",
      "[7484]\n",
      "[3740]\n",
      "[9712]\n",
      "[13820]\n",
      "[2181]\n",
      "[5247]\n",
      "[3912]\n",
      "[3165]\n",
      "[4320]\n",
      "[30563]\n",
      "[6362]\n",
      "[1785]\n",
      "[3043]\n",
      "[14412]\n",
      "[7485]\n",
      "[2926]\n",
      "[11211]\n",
      "[1900]\n",
      "[4271]\n",
      "[20795]\n",
      "[1729]\n",
      "[7618]\n",
      "[12184]\n",
      "[12105]\n",
      "[4020]\n",
      "[18855]\n",
      "[4549]\n",
      "[1565]\n",
      "[2606]\n",
      "[19791]\n",
      "[6946]\n",
      "[16991]\n",
      "[3487]\n",
      "[14210]\n",
      "[3783]\n",
      "[4620]\n",
      "[8692]\n",
      "[15756]\n",
      "[4073]\n",
      "[5085]\n",
      "[7901]\n",
      "[19485]\n",
      "[2962]\n",
      "[4412]\n",
      "[20444]\n",
      "[10996]\n",
      "[3880]\n",
      "[7153]\n",
      "[9696]\n",
      "[4053]\n",
      "[4404]\n",
      "[5777]\n",
      "[9088]\n",
      "[20776]\n",
      "[8905]\n",
      "[4675]\n",
      "[4425]\n",
      "[6624]\n",
      "[3134]\n",
      "[5531]\n",
      "[8961]\n",
      "[6447]\n",
      "[2714]\n",
      "[6910]\n",
      "[6278]\n",
      "[12628]\n",
      "[14785]\n",
      "[11023]\n",
      "[20502]\n",
      "[5162]\n",
      "[4980]\n",
      "[4272]\n",
      "[3343]\n",
      "[9961]\n",
      "[5164]\n",
      "[3743]\n",
      "[5535]\n",
      "[25428]\n",
      "[18446]\n",
      "[2467]\n",
      "[12241]\n",
      "[5392]\n",
      "[2860]\n",
      "[26523]\n",
      "[21263]\n",
      "[6382]\n",
      "[3236]\n",
      "[21868]\n",
      "[5508]\n",
      "[11840]\n",
      "[7159]\n",
      "[5400]\n",
      "[20149]\n",
      "[5533]\n",
      "[16734]\n",
      "[9403]\n",
      "[12527]\n",
      "[6298]\n",
      "[9949]\n",
      "[4190]\n",
      "[16491]\n",
      "[5550]\n",
      "[3640]\n",
      "[16559]\n",
      "[5254]\n",
      "[2492]\n",
      "[4355]\n",
      "[10238]\n",
      "[20481]\n",
      "[5697]\n",
      "[2320]\n",
      "[11707]\n",
      "[1802]\n",
      "[6846]\n",
      "[8079]\n",
      "[3773]\n",
      "[3433]\n",
      "[2410]\n",
      "[5562]\n",
      "[3040]\n",
      "[7673]\n",
      "[4997]\n",
      "[7140]\n",
      "[7915]\n",
      "[1642]\n",
      "[6322]\n",
      "[3330]\n",
      "[2341]\n",
      "[8873]\n",
      "[4029]\n",
      "[6324]\n",
      "[3551]\n",
      "[5585]\n",
      "[17938]\n",
      "[4878]\n",
      "[1577]\n",
      "[6870]\n",
      "[4050]\n",
      "[5983]\n",
      "[13118]\n",
      "[23509]\n",
      "[11021]\n",
      "[8814]\n",
      "[7112]\n",
      "[9693]\n",
      "[2199]\n",
      "[1903]\n",
      "[15996]\n",
      "[4868]\n",
      "[6388]\n",
      "[7253]\n",
      "[15740]\n",
      "[3850]\n",
      "[8376]\n",
      "[6714]\n",
      "[25947]\n",
      "[12079]\n",
      "[3756]\n",
      "[7367]\n",
      "[2557]\n",
      "[3484]\n",
      "[7320]\n",
      "[11333]\n",
      "[16518]\n",
      "[2653]\n",
      "[3929]\n",
      "[4811]\n",
      "[13712]\n",
      "[5075]\n",
      "[8323]\n",
      "[11864]\n",
      "[14568]\n",
      "[19557]\n",
      "[1688]\n",
      "[3169]\n",
      "[5895]\n",
      "[3854]\n",
      "[8168]\n",
      "[2114]\n",
      "[2757]\n",
      "[17356]\n",
      "[13182]\n",
      "[3312]\n",
      "[9360]\n",
      "[4376]\n",
      "[4366]\n",
      "[5744]\n",
      "[3872]\n",
      "[9303]\n",
      "[6627]\n",
      "[4354]\n",
      "[19929]\n",
      "[15842]\n",
      "[3264]\n",
      "[5564]\n",
      "[7122]\n",
      "[8554]\n",
      "[3422]\n",
      "[5122]\n",
      "[5499]\n",
      "[4422]\n",
      "[13332]\n",
      "[8346]\n",
      "[2551]\n",
      "[8769]\n",
      "[11466]\n",
      "[3742]\n",
      "[8223]\n",
      "[10901]\n",
      "[17060]\n",
      "[23326]\n",
      "[23049]\n",
      "[14782]\n",
      "[6845]\n",
      "[5670]\n",
      "[2109]\n",
      "[3955]\n",
      "[16677]\n",
      "[4104]\n",
      "[19206]\n",
      "[1675]\n",
      "[1200]\n",
      "[7248]\n",
      "[4041]\n",
      "[2591]\n",
      "[6232]\n",
      "[12765]\n",
      "[9201]\n",
      "[2844]\n",
      "[4052]\n",
      "[6737]\n",
      "[6842]\n",
      "[4210]\n",
      "[15369]\n",
      "[1952]\n",
      "[11783]\n",
      "[10089]\n",
      "[17070]\n",
      "[7646]\n",
      "[14499]\n",
      "[6070]\n",
      "[8134]\n",
      "[10498]\n",
      "[5363]\n",
      "[1269]\n",
      "[21374]\n",
      "[11699]\n",
      "[28569]\n",
      "[4295]\n",
      "[1735]\n",
      "[10108]\n",
      "[4626]\n",
      "[7343]\n",
      "[14995]\n",
      "[1989]\n",
      "[3067]\n",
      "[10722]\n",
      "[14053]\n",
      "[7878]\n",
      "[6542]\n",
      "[6252]\n",
      "[3399]\n",
      "[6402]\n",
      "[15624]\n",
      "[18701]\n",
      "[2210]\n",
      "[26879]\n",
      "[20326]\n",
      "[3741]\n",
      "[13318]\n",
      "[15639]\n",
      "[15281]\n",
      "[26676]\n",
      "[13987]\n",
      "[12780]\n",
      "[19150]\n",
      "[7961]\n",
      "[12545]\n",
      "[3733]\n",
      "[3447]\n",
      "[3404]\n",
      "[3511]\n",
      "[11178]\n",
      "[13099]\n",
      "[10780]\n",
      "[7201]\n",
      "[12440]\n",
      "[4986]\n",
      "[7265]\n",
      "[5235]\n",
      "[14228]\n",
      "[7929]\n",
      "[18786]\n",
      "[10762]\n",
      "[16396]\n",
      "[5502]\n",
      "[11522]\n",
      "[3376]\n",
      "[2313]\n",
      "[27696]\n",
      "[2375]\n",
      "[7346]\n",
      "[20482]\n",
      "[19790]\n",
      "[8924]\n",
      "[26006]\n",
      "[4820]\n",
      "[19359]\n",
      "[4146]\n",
      "[6335]\n",
      "[3094]\n",
      "[17633]\n",
      "[14895]\n",
      "[1678]\n",
      "[4871]\n",
      "[15477]\n",
      "[11973]\n",
      "[4346]\n",
      "[1763]\n",
      "[7754]\n",
      "[2887]\n",
      "[14295]\n",
      "[7778]\n",
      "[19718]\n",
      "[7415]\n",
      "[3816]\n",
      "[9243]\n",
      "[3598]\n",
      "[5893]\n",
      "[3389]\n",
      "[10240]\n",
      "[2520]\n",
      "[7240]\n",
      "[5105]\n",
      "[9003]\n",
      "[2740]\n",
      "[16541]\n",
      "[4236]\n",
      "[4373]\n",
      "[3097]\n",
      "[10096]\n",
      "[27399]\n",
      "[27382]\n",
      "[3201]\n",
      "[10586]\n",
      "[11501]\n",
      "[20077]\n",
      "[1932]\n",
      "[10546]\n",
      "[6617]\n",
      "[3430]\n",
      "[12266]\n",
      "[9174]\n",
      "[9812]\n",
      "[14736]\n",
      "[12856]\n",
      "[13437]\n",
      "[13587]\n",
      "[6641]\n",
      "[6079]\n",
      "[5140]\n",
      "[4144]\n",
      "[9453]\n",
      "[17846]\n",
      "[15513]\n",
      "[5260]\n",
      "[7203]\n",
      "[3920]\n",
      "[4707]\n",
      "[10789]\n",
      "[4334]\n",
      "[11223]\n",
      "[26729]\n",
      "[3064]\n",
      "[30353]\n",
      "[2911]\n",
      "[12204]\n",
      "[30876]\n",
      "[14205]\n",
      "[30735]\n",
      "[14554]\n",
      "[6151]\n",
      "[4548]\n",
      "[9532]\n",
      "[19181]\n",
      "[23117]\n",
      "[8311]\n",
      "[16547]\n",
      "[16967]\n",
      "[4541]\n",
      "[10799]\n",
      "[3990]\n",
      "[12569]\n",
      "[19739]\n",
      "[11076]\n",
      "[12265]\n",
      "[4849]\n",
      "[25489]\n",
      "[4281]\n",
      "[6809]\n",
      "[4002]\n",
      "[6129]\n",
      "[15287]\n",
      "[3922]\n",
      "[4721]\n",
      "[3503]\n",
      "[1863]\n",
      "[6103]\n",
      "[5032]\n",
      "[1753]\n",
      "[15240]\n",
      "[4027]\n",
      "[7695]\n",
      "[18070]\n",
      "[7959]\n",
      "[7175]\n",
      "[5490]\n",
      "[1311]\n",
      "[8309]\n",
      "[4928]\n",
      "[10026]\n",
      "[4880]\n",
      "[4637]\n",
      "[5505]\n",
      "[5000]\n",
      "[20696]\n",
      "[11822]\n",
      "[9573]\n",
      "[25629]\n",
      "[8776]\n",
      "[7299]\n",
      "[10119]\n",
      "[4181]\n",
      "[7025]\n",
      "[10650]\n",
      "[9284]\n",
      "[2808]\n",
      "[6423]\n",
      "[22170]\n",
      "[4221]\n",
      "[3435]\n",
      "[10821]\n",
      "[4944]\n",
      "[9001]\n",
      "[2459]\n",
      "[10728]\n",
      "[4899]\n",
      "[24184]\n",
      "[15472]\n",
      "[14422]\n",
      "[7739]\n",
      "[11127]\n",
      "[5727]\n",
      "[10440]\n",
      "[5510]\n",
      "[9159]\n",
      "[6462]\n",
      "[9103]\n",
      "[29811]\n",
      "[1377]\n",
      "[9616]\n",
      "[5321]\n",
      "[6008]\n",
      "[28578]\n",
      "[3216]\n",
      "[12238]\n",
      "[13665]\n",
      "[3684]\n",
      "[17461]\n",
      "[4893]\n",
      "[5734]\n",
      "[9052]\n",
      "[10378]\n",
      "[7942]\n",
      "[22776]\n",
      "[28145]\n",
      "[4116]\n",
      "[2999]\n",
      "[14550]\n",
      "[14662]\n",
      "[22472]\n",
      "[2485]\n",
      "[9179]\n",
      "[6346]\n",
      "[13323]\n",
      "[6695]\n",
      "[14648]\n",
      "[7782]\n",
      "[14459]\n",
      "[9161]\n",
      "[7275]\n",
      "[7053]\n",
      "[24274]\n",
      "[20125]\n",
      "[21935]\n",
      "[8956]\n",
      "[14659]\n",
      "[23970]\n",
      "[14504]\n",
      "[10193]\n",
      "[8526]\n",
      "[19175]\n",
      "[3034]\n",
      "[6331]\n",
      "[9926]\n",
      "[6383]\n",
      "[6200]\n",
      "[10938]\n",
      "[13733]\n",
      "[8728]\n",
      "[1902]\n",
      "[13032]\n",
      "[11881]\n",
      "[11686]\n",
      "[3622]\n",
      "[4287]\n",
      "[7014]\n",
      "[27442]\n",
      "[12945]\n",
      "[16263]\n",
      "[12519]\n",
      "[21042]\n",
      "[7530]\n",
      "[22945]\n",
      "[4344]\n",
      "[6676]\n",
      "[3881]\n",
      "[9108]\n",
      "[13020]\n",
      "[27836]\n",
      "[9889]\n",
      "[17135]\n",
      "[14258]\n",
      "[12626]\n",
      "[13117]\n",
      "[13233]\n",
      "[5287]\n",
      "[5349]\n",
      "[5040]\n",
      "[18028]\n",
      "[12426]\n",
      "[6439]\n",
      "[4686]\n",
      "[2233]\n",
      "[11907]\n",
      "[5891]\n",
      "[7315]\n",
      "[9901]\n",
      "[3100]\n",
      "[5567]\n",
      "[11968]\n",
      "[2756]\n",
      "[19192]\n",
      "[4746]\n",
      "[8162]\n",
      "[8580]\n",
      "[22281]\n",
      "[17727]\n",
      "[6364]\n",
      "[4406]\n",
      "[13708]\n",
      "[5779]\n",
      "[9965]\n",
      "[20517]\n",
      "[6864]\n",
      "[8500]\n",
      "[21735]\n",
      "[14798]\n",
      "[7283]\n",
      "[3524]\n",
      "[6465]\n",
      "[2268]\n",
      "[15426]\n",
      "[20078]\n",
      "[9555]\n",
      "[10568]\n",
      "[13328]\n",
      "[10243]\n",
      "[26194]\n",
      "[6517]\n",
      "[5976]\n",
      "[9813]\n",
      "[30856]\n",
      "[8113]\n",
      "[6970]\n",
      "[10234]\n",
      "[5659]\n",
      "[11218]\n",
      "[9830]\n",
      "[20592]\n",
      "[13139]\n",
      "[10391]\n",
      "[29921]\n",
      "[5602]\n",
      "[18535]\n",
      "[18209]\n",
      "[4697]\n",
      "[13180]\n",
      "[3462]\n",
      "[6188]\n",
      "[21763]\n",
      "[11792]\n",
      "[5296]\n",
      "[9207]\n",
      "[12617]\n",
      "[4482]\n",
      "[18119]\n",
      "[16329]\n",
      "[24448]\n",
      "[20398]\n",
      "[6371]\n",
      "[12517]\n",
      "[7414]\n",
      "[18672]\n",
      "[11122]\n",
      "[8913]\n",
      "[16383]\n",
      "[7545]\n",
      "[5241]\n",
      "[10196]\n",
      "[14518]\n",
      "[8272]\n",
      "[30378]\n",
      "[10806]\n",
      "[16017]\n",
      "[19227]\n",
      "[17030]\n",
      "[13072]\n",
      "[9225]\n",
      "[8793]\n",
      "[10399]\n",
      "[21859]\n",
      "[13685]\n",
      "[17799]\n",
      "[4744]\n",
      "[4393]\n",
      "[12568]\n",
      "[6962]\n",
      "[13888]\n",
      "[22624]\n",
      "[3964]\n",
      "[12841]\n",
      "[7990]\n",
      "[3257]\n",
      "[13304]\n",
      "[19012]\n",
      "[12697]\n",
      "[4711]\n",
      "[5414]\n",
      "[9892]\n",
      "[15290]\n",
      "[14723]\n",
      "[8640]\n",
      "[12168]\n",
      "[14827]\n",
      "[18002]\n",
      "[10730]\n",
      "[28414]\n",
      "[4553]\n",
      "[2508]\n",
      "[25048]\n",
      "[28018]\n",
      "[8238]\n",
      "[8799]\n",
      "[15113]\n",
      "[4631]\n",
      "[4873]\n",
      "[10129]\n",
      "[11509]\n",
      "[8933]\n",
      "[5714]\n",
      "[6721]\n",
      "[3611]\n",
      "[19124]\n",
      "[6263]\n",
      "[1687]\n",
      "[4470]\n",
      "[4547]\n",
      "[14022]\n",
      "[13534]\n",
      "[5318]\n",
      "[12347]\n",
      "[10473]\n",
      "[6032]\n",
      "[12559]\n",
      "[9946]\n",
      "[15010]\n",
      "[4513]\n",
      "[12562]\n",
      "[6789]\n",
      "[20469]\n",
      "[3120]\n",
      "[5991]\n",
      "[13184]\n",
      "[8802]\n",
      "[9106]\n",
      "[11618]\n",
      "[7937]\n",
      "[9947]\n",
      "[9093]\n",
      "[24312]\n",
      "[5325]\n",
      "[15495]\n",
      "[20430]\n",
      "[7997]\n",
      "[8831]\n",
      "[1971]\n",
      "[15859]\n",
      "[18422]\n",
      "[23329]\n",
      "[8312]\n",
      "[5372]\n",
      "[11290]\n",
      "[6217]\n",
      "[5704]\n",
      "[6921]\n",
      "[4039]\n",
      "[17249]\n",
      "[8433]\n",
      "[7587]\n",
      "[10287]\n",
      "[7443]\n",
      "[24374]\n",
      "[15526]\n",
      "[6435]\n",
      "[14879]\n",
      "[4441]\n",
      "[20318]\n",
      "[6437]\n",
      "[13048]\n",
      "[3643]\n",
      "[6851]\n",
      "[2282]\n",
      "[9316]\n",
      "[20101]\n",
      "[16240]\n",
      "[3351]\n",
      "[11025]\n",
      "[13977]\n",
      "[10949]\n",
      "[3669]\n",
      "[6160]\n",
      "[4757]\n",
      "[5755]\n",
      "[3813]\n",
      "[5051]\n",
      "[20865]\n",
      "[20801]\n",
      "[17541]\n",
      "[14505]\n",
      "[3485]\n",
      "[9211]\n",
      "[4067]\n",
      "[8794]\n",
      "[7245]\n",
      "[11888]\n",
      "[3838]\n",
      "[13365]\n",
      "[13313]\n",
      "[16207]\n",
      "[7102]\n",
      "[2278]\n",
      "[27614]\n",
      "[17176]\n",
      "[17084]\n",
      "[9967]\n",
      "[16866]\n",
      "[9690]\n",
      "[19914]\n",
      "[13154]\n",
      "[21235]\n",
      "[27565]\n",
      "[26013]\n",
      "[9127]\n",
      "[12615]\n",
      "[2272]\n",
      "[11377]\n",
      "[8215]\n",
      "[22772]\n",
      "[7286]\n",
      "[24558]\n",
      "[22708]\n",
      "[17192]\n",
      "[6108]\n",
      "[5591]\n",
      "[13330]\n",
      "[3842]\n",
      "[15977]\n",
      "[8234]\n",
      "[3209]\n",
      "[24828]\n",
      "[6393]\n",
      "[15901]\n",
      "[17720]\n",
      "[8475]\n",
      "[18502]\n",
      "[4220]\n",
      "[10513]\n",
      "[7987]\n",
      "[10389]\n",
      "[25127]\n",
      "[10685]\n",
      "[18245]\n",
      "[18917]\n",
      "[29533]\n",
      "[5972]\n",
      "[22406]\n",
      "[19900]\n",
      "[3296]\n",
      "[9083]\n",
      "[6640]\n",
      "[17864]\n",
      "[10233]\n",
      "[25998]\n",
      "[7537]\n",
      "[17342]\n",
      "[5807]\n",
      "[6471]\n",
      "[6770]\n",
      "[8164]\n",
      "[6237]\n",
      "[18742]\n",
      "[22520]\n",
      "[12352]\n",
      "[15731]\n",
      "[4336]\n",
      "[22840]\n",
      "[9691]\n",
      "[13143]\n",
      "[1927]\n",
      "[26161]\n",
      "[3905]\n",
      "[20536]\n",
      "[29393]\n",
      "[6868]\n",
      "[2875]\n",
      "[29230]\n",
      "[7973]\n",
      "[9047]\n",
      "[6613]\n",
      "[5225]\n",
      "[17012]\n",
      "[6054]\n",
      "[9990]\n",
      "[3]\n",
      "[21488]\n",
      "[9007]\n",
      "[9879]\n",
      "[7010]\n",
      "[14005]\n",
      "[10754]\n",
      "[23621]\n",
      "[9606]\n",
      "[13935]\n",
      "[4473]\n",
      "[8386]\n",
      "[18175]\n",
      "[8434]\n",
      "[2248]\n",
      "[16098]\n",
      "[9232]\n",
      "[4648]\n",
      "[9734]\n",
      "[11074]\n",
      "[8957]\n",
      "[24850]\n",
      "[21646]\n",
      "[25304]\n",
      "[8413]\n",
      "[26588]\n",
      "[5072]\n",
      "[8329]\n",
      "[6415]\n",
      "[22734]\n",
      "[5990]\n",
      "[17801]\n",
      "[13219]\n",
      "[13571]\n",
      "[5277]\n",
      "[19496]\n",
      "[10805]\n",
      "[15678]\n",
      "[5843]\n",
      "[10951]\n",
      "[5752]\n",
      "[13590]\n",
      "[15787]\n",
      "[12539]\n",
      "[14293]\n",
      "[16319]\n",
      "[22815]\n",
      "[15530]\n",
      "[11581]\n",
      "[18519]\n",
      "[7342]\n",
      "[6905]\n",
      "[9265]\n",
      "[29751]\n",
      "[9262]\n",
      "[5103]\n",
      "[9043]\n",
      "[8718]\n",
      "[14560]\n",
      "[1985]\n",
      "[6183]\n",
      "[12283]\n",
      "[15438]\n",
      "[5938]\n",
      "[12493]\n",
      "[13937]\n",
      "[21095]\n",
      "[8717]\n",
      "[8765]\n",
      "[1534]\n",
      "[9536]\n",
      "[5664]\n",
      "[7217]\n",
      "[30646]\n",
      "[17324]\n",
      "[3]\n",
      "[8086]\n",
      "[14313]\n",
      "[18117]\n",
      "[6339]\n",
      "[11984]\n",
      "[17878]\n",
      "[14072]\n",
      "[12349]\n",
      "[9293]\n",
      "[13944]\n",
      "[20299]\n",
      "[17067]\n",
      "[19220]\n",
      "[16700]\n",
      "[2683]\n",
      "[7647]\n",
      "[22902]\n",
      "[12232]\n",
      "[5696]\n",
      "[12645]\n",
      "[9882]\n",
      "[19799]\n",
      "[7606]\n",
      "[5175]\n",
      "[7059]\n",
      "[21216]\n",
      "[7259]\n",
      "[8782]\n",
      "[11341]\n",
      "[10798]\n",
      "[12157]\n",
      "[13004]\n",
      "[29263]\n",
      "[6247]\n",
      "[10114]\n",
      "[18390]\n",
      "[7106]\n",
      "[3385]\n",
      "[11567]\n",
      "[2830]\n",
      "[5023]\n",
      "[23068]\n",
      "[22878]\n",
      "[24512]\n",
      "[14915]\n",
      "[10516]\n",
      "[4136]\n",
      "[7780]\n",
      "[15807]\n",
      "[28159]\n",
      "[14800]\n",
      "[21494]\n",
      "[11428]\n",
      "[4535]\n",
      "[10926]\n",
      "[19144]\n",
      "[7322]\n",
      "[14270]\n",
      "[22416]\n",
      "[5731]\n",
      "[20985]\n",
      "[3392]\n",
      "[8077]\n",
      "[6126]\n",
      "[12456]\n",
      "[15911]\n",
      "[3306]\n",
      "[13648]\n",
      "[13470]\n",
      "[3141]\n",
      "[14439]\n",
      "[13007]\n",
      "[7941]\n",
      "[12511]\n",
      "[14432]\n",
      "[10419]\n",
      "[11461]\n",
      "[4330]\n",
      "[29577]\n",
      "[5767]\n",
      "[27035]\n",
      "[11611]\n",
      "[17676]\n",
      "[5792]\n",
      "[9344]\n",
      "[22415]\n",
      "[10218]\n",
      "[16864]\n",
      "[4345]\n",
      "[14000]\n",
      "[7331]\n",
      "[3875]\n",
      "[16318]\n",
      "[16485]\n",
      "[11658]\n",
      "[30733]\n",
      "[2344]\n",
      "[8617]\n",
      "[17263]\n",
      "[12387]\n",
      "[2489]\n",
      "[11927]\n",
      "[3]\n",
      "[15308]\n",
      "[14218]\n",
      "[4494]\n",
      "[6552]\n",
      "[8661]\n",
      "[7338]\n",
      "[21409]\n",
      "[7899]\n",
      "[12888]\n",
      "[5736]\n",
      "[12086]\n",
      "[21829]\n",
      "[5980]\n",
      "[26320]\n",
      "[7574]\n",
      "[7699]\n",
      "[10913]\n",
      "[6728]\n",
      "[3540]\n",
      "[6668]\n",
      "[27552]\n",
      "[7390]\n",
      "[13476]\n",
      "[4564]\n",
      "[12123]\n",
      "[27705]\n",
      "[11112]\n",
      "[10241]\n",
      "[21304]\n",
      "[10632]\n",
      "[23495]\n",
      "[9216]\n",
      "[7400]\n",
      "[26000]\n",
      "[12843]\n",
      "[12414]\n",
      "[14382]\n",
      "[19645]\n",
      "[14893]\n",
      "[14553]\n",
      "[22924]\n",
      "[10841]\n",
      "[5118]\n",
      "[10950]\n",
      "[28948]\n",
      "[13831]\n",
      "[13854]\n",
      "[2655]\n",
      "[15006]\n",
      "[10221]\n",
      "[7116]\n",
      "[17312]\n",
      "[10767]\n",
      "[10891]\n",
      "[21691]\n",
      "[21510]\n",
      "[14502]\n",
      "[19169]\n",
      "[9028]\n",
      "[13666]\n",
      "[11747]\n",
      "[13098]\n",
      "[17645]\n",
      "[4163]\n",
      "[14435]\n",
      "[11220]\n",
      "[16873]\n",
      "[15112]\n",
      "[13989]\n",
      "[14172]\n",
      "[3]\n",
      "[7823]\n",
      "[1435]\n",
      "[18487]\n",
      "[17904]\n",
      "[17746]\n",
      "[13711]\n",
      "[6480]\n",
      "[13169]\n",
      "[9132]\n",
      "[4718]\n",
      "[7344]\n",
      "[9152]\n",
      "[11718]\n",
      "[9576]\n",
      "[7384]\n",
      "[22129]\n",
      "[15612]\n",
      "[12062]\n",
      "[10827]\n",
      "[4802]\n",
      "[18932]\n",
      "[18432]\n",
      "[18341]\n",
      "[1498]\n",
      "[16025]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f44ac7e110f43c78ee18ae82b8479d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original list len: 515 select list len: 508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f924e7e6223845938f9d72988b7e9fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16287]\n",
      "[9469]\n",
      "[26549]\n",
      "[25370]\n",
      "[13881]\n",
      "[16715]\n",
      "[12884]\n",
      "[18276]\n",
      "[18873]\n",
      "[25913]\n",
      "[14178]\n",
      "[26590]\n",
      "[15324]\n",
      "[19947]\n",
      "[28904]\n",
      "[25112]\n",
      "[14983]\n",
      "[10548]\n",
      "[28631]\n",
      "[19809]\n",
      "[24443]\n",
      "[16648]\n",
      "[5646]\n",
      "[26808]\n",
      "[13071]\n",
      "[21953]\n",
      "[24950]\n",
      "[16517]\n",
      "[5630]\n",
      "[30330]\n",
      "[17936]\n",
      "[18658]\n",
      "[23903]\n",
      "[22641]\n",
      "[11769]\n",
      "[22329]\n",
      "[20061]\n",
      "[24504]\n",
      "[18817]\n",
      "[25422]\n",
      "[13189]\n",
      "[13205]\n",
      "[30712]\n",
      "[30473]\n",
      "[11941]\n",
      "[28715]\n",
      "[11053]\n",
      "[21570]\n",
      "[9039]\n",
      "[22834]\n",
      "[18894]\n",
      "[26004]\n",
      "[26745]\n",
      "[20740]\n",
      "[10468]\n",
      "[29842]\n",
      "[11331]\n",
      "[12006]\n",
      "[30476]\n",
      "[30327]\n",
      "[26629]\n",
      "[26452]\n",
      "[10925]\n",
      "[23712]\n",
      "[21281]\n",
      "[12790]\n",
      "[24780]\n",
      "[14384]\n",
      "[16480]\n",
      "[15646]\n",
      "[22952]\n",
      "[25377]\n",
      "[30079]\n",
      "[18132]\n",
      "[12495]\n",
      "[3245]\n",
      "[30588]\n",
      "[11943]\n",
      "[14545]\n",
      "[19962]\n",
      "[23589]\n",
      "[9840]\n",
      "[13254]\n",
      "[19292]\n",
      "[13302]\n",
      "[28090]\n",
      "[25041]\n",
      "[14363]\n",
      "[10865]\n",
      "[30751]\n",
      "[28006]\n",
      "[28276]\n",
      "[7285]\n",
      "[9328]\n",
      "[26842]\n",
      "[24051]\n",
      "[11594]\n",
      "[15421]\n",
      "[27341]\n",
      "[7039]\n",
      "[10040]\n",
      "[30308]\n",
      "[13795]\n",
      "[13355]\n",
      "[18835]\n",
      "[26982]\n",
      "[20205]\n",
      "[4252]\n",
      "[24357]\n",
      "[16987]\n",
      "[11535]\n",
      "[27905]\n",
      "[8020]\n",
      "[27554]\n",
      "[8236]\n",
      "[13391]\n",
      "[25716]\n",
      "[28637]\n",
      "[16466]\n",
      "[18235]\n",
      "[25306]\n",
      "[21936]\n",
      "[30798]\n",
      "[24808]\n",
      "[28331]\n",
      "[11421]\n",
      "[11516]\n",
      "[16130]\n",
      "[28822]\n",
      "[30533]\n",
      "[14359]\n",
      "[17669]\n",
      "[10435]\n",
      "[23431]\n",
      "[11209]\n",
      "[12169]\n",
      "[26354]\n",
      "[13693]\n",
      "[20340]\n",
      "[18459]\n",
      "[24569]\n",
      "[29256]\n",
      "[12491]\n",
      "[27947]\n",
      "[13484]\n",
      "[29492]\n",
      "[29420]\n",
      "[29889]\n",
      "[22262]\n",
      "[11312]\n",
      "[14799]\n",
      "[5096]\n",
      "[26251]\n",
      "[18071]\n",
      "[25649]\n",
      "[14904]\n",
      "[18044]\n",
      "[28770]\n",
      "[8149]\n",
      "[27864]\n",
      "[29355]\n",
      "[15795]\n",
      "[26398]\n",
      "[15273]\n",
      "[16512]\n",
      "[13076]\n",
      "[5245]\n",
      "[16549]\n",
      "[26259]\n",
      "[28596]\n",
      "[23147]\n",
      "[27404]\n",
      "[22932]\n",
      "[14374]\n",
      "[15489]\n",
      "[11164]\n",
      "[22569]\n",
      "[14599]\n",
      "[15021]\n",
      "[27590]\n",
      "[24555]\n",
      "[5405]\n",
      "[16815]\n",
      "[17446]\n",
      "[1672]\n",
      "[29519]\n",
      "[1836]\n",
      "[29296]\n",
      "[24231]\n",
      "[7110]\n",
      "[19593]\n",
      "[8609]\n",
      "[29067]\n",
      "[27266]\n",
      "[9426]\n",
      "[25491]\n",
      "[15516]\n",
      "[15506]\n",
      "[21020]\n",
      "[15857]\n",
      "[17407]\n",
      "[15710]\n",
      "[16669]\n",
      "[2731]\n",
      "[13953]\n",
      "[30742]\n",
      "[23422]\n",
      "[6765]\n",
      "[11263]\n",
      "[11475]\n",
      "[3099]\n",
      "[29276]\n",
      "[16418]\n",
      "[29404]\n",
      "[20142]\n",
      "[9716]\n",
      "[16064]\n",
      "[13003]\n",
      "[18885]\n",
      "[23443]\n",
      "[30864]\n",
      "[19464]\n",
      "[20127]\n",
      "[17829]\n",
      "[19148]\n",
      "[14704]\n",
      "[21160]\n",
      "[27862]\n",
      "[16170]\n",
      "[29759]\n",
      "[25465]\n",
      "[18671]\n",
      "[18386]\n",
      "[17103]\n",
      "[24159]\n",
      "[14880]\n",
      "[26765]\n",
      "[22294]\n",
      "[18544]\n",
      "[22572]\n",
      "[29331]\n",
      "[26651]\n",
      "[28146]\n",
      "[8105]\n",
      "[12745]\n",
      "[11928]\n",
      "[21852]\n",
      "[19709]\n",
      "[29673]\n",
      "[24638]\n",
      "[29556]\n",
      "[24742]\n",
      "[13333]\n",
      "[9607]\n",
      "[21253]\n",
      "[15995]\n",
      "[15630]\n",
      "[26905]\n",
      "[21008]\n",
      "[7324]\n",
      "[23642]\n",
      "[25695]\n",
      "[24489]\n",
      "[24783]\n",
      "[24270]\n",
      "[12936]\n",
      "[25226]\n",
      "[26776]\n",
      "[10616]\n",
      "[18158]\n",
      "[10878]\n",
      "[19888]\n",
      "[12464]\n",
      "[14706]\n",
      "[13767]\n",
      "[10596]\n",
      "[5620]\n",
      "[23243]\n",
      "[21386]\n",
      "[2415]\n",
      "[23610]\n",
      "[13608]\n",
      "[11533]\n",
      "[16751]\n",
      "[12090]\n",
      "[15896]\n",
      "[25554]\n",
      "[14024]\n",
      "[15964]\n",
      "[11817]\n",
      "[17256]\n",
      "[16881]\n",
      "[23665]\n",
      "[21812]\n",
      "[20770]\n",
      "[7943]\n",
      "[30827]\n",
      "[17453]\n",
      "[17158]\n",
      "[5730]\n",
      "[15312]\n",
      "[5109]\n",
      "[13012]\n",
      "[17621]\n",
      "[22365]\n",
      "[14478]\n",
      "[11061]\n",
      "[7787]\n",
      "[7680]\n",
      "[21438]\n",
      "[4209]\n",
      "[25890]\n",
      "[20706]\n",
      "[12721]\n",
      "[27628]\n",
      "[21462]\n",
      "[30753]\n",
      "[27764]\n",
      "[29502]\n",
      "[13290]\n",
      "[23523]\n",
      "[13462]\n",
      "[10519]\n",
      "[9851]\n",
      "[24628]\n",
      "[12751]\n",
      "[12774]\n",
      "[13516]\n",
      "[16650]\n",
      "[24235]\n",
      "[19213]\n",
      "[4369]\n",
      "[6163]\n",
      "[30232]\n",
      "[18734]\n",
      "[8606]\n",
      "[11976]\n",
      "[21684]\n",
      "[19051]\n",
      "[26665]\n",
      "[21825]\n",
      "[12649]\n",
      "[14031]\n",
      "[9231]\n",
      "[22095]\n",
      "[18288]\n",
      "[15454]\n",
      "[9055]\n",
      "[5649]\n",
      "[23719]\n",
      "[29794]\n",
      "[18958]\n",
      "[15214]\n",
      "[25686]\n",
      "[11511]\n",
      "[12892]\n",
      "[28518]\n",
      "[29401]\n",
      "[4513]\n",
      "[28243]\n",
      "[21990]\n",
      "[3946]\n",
      "[29835]\n",
      "[1845]\n",
      "[27964]\n",
      "[25424]\n",
      "[21515]\n",
      "[25137]\n",
      "[29852]\n",
      "[9817]\n",
      "[20753]\n",
      "[9309]\n",
      "[15557]\n",
      "[11890]\n",
      "[9180]\n",
      "[18173]\n",
      "[19323]\n",
      "[12682]\n",
      "[21664]\n",
      "[18659]\n",
      "[27542]\n",
      "[9370]\n",
      "[9294]\n",
      "[16366]\n",
      "[24737]\n",
      "[9727]\n",
      "[11587]\n",
      "[23519]\n",
      "[11476]\n",
      "[8070]\n",
      "[6132]\n",
      "[9906]\n",
      "[14964]\n",
      "[13336]\n",
      "[22021]\n",
      "[24529]\n",
      "[20017]\n",
      "[23989]\n",
      "[19915]\n",
      "[24770]\n",
      "[15834]\n",
      "[21170]\n",
      "[25507]\n",
      "[10456]\n",
      "[22162]\n",
      "[19938]\n",
      "[12669]\n",
      "[12618]\n",
      "[17091]\n",
      "[4642]\n",
      "[22157]\n",
      "[24610]\n",
      "[5114]\n",
      "[8391]\n",
      "[15028]\n",
      "[26730]\n",
      "[30859]\n",
      "[21175]\n",
      "[29365]\n",
      "[19540]\n",
      "[22078]\n",
      "[15048]\n",
      "[29402]\n",
      "[24019]\n",
      "[27620]\n",
      "[27351]\n",
      "[12451]\n",
      "[14612]\n",
      "[3831]\n",
      "[2807]\n",
      "[21864]\n",
      "[12629]\n",
      "[17127]\n",
      "[30355]\n",
      "[26168]\n",
      "[8715]\n",
      "[27356]\n",
      "[7521]\n",
      "[10002]\n",
      "[7404]\n",
      "[8492]\n",
      "[30164]\n",
      "[15471]\n",
      "[25142]\n",
      "[16714]\n",
      "[24043]\n",
      "[26695]\n",
      "[12188]\n",
      "[18118]\n",
      "[27392]\n",
      "[26599]\n",
      "[23468]\n",
      "[18200]\n",
      "[11999]\n",
      "[23964]\n",
      "[11523]\n",
      "[22946]\n",
      "[27051]\n",
      "[30619]\n",
      "[28521]\n",
      "[28537]\n",
      "[28542]\n",
      "[24384]\n",
      "[7663]\n",
      "[30313]\n",
      "[25005]\n",
      "[19130]\n",
      "[16277]\n",
      "[21535]\n",
      "[9818]\n",
      "[4817]\n",
      "[25123]\n",
      "[15370]\n",
      "[18714]\n",
      "[25246]\n",
      "[23221]\n",
      "[25615]\n",
      "[30514]\n",
      "[27106]\n",
      "[19198]\n",
      "[12507]\n",
      "[18496]\n",
      "[22108]\n",
      "[16226]\n",
      "[13379]\n",
      "[22561]\n",
      "[2152]\n",
      "[13717]\n",
      "[6355]\n",
      "[11463]\n",
      "[15473]\n",
      "[19529]\n",
      "[8043]\n",
      "[24065]\n",
      "[26178]\n",
      "[13564]\n",
      "[17254]\n",
      "[29531]\n",
      "[20250]\n",
      "[4643]\n",
      "[14362]\n",
      "[24208]\n",
      "[11947]\n",
      "[17899]\n",
      "[26114]\n",
      "[14758]\n",
      "[27501]\n",
      "[30443]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfaed124f81a48bfa3b3425250d070aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original list len: 646 select list len: 627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a17284623e54c8cbef535ec11cc7358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7385, 2471]\n",
      "[26376, 30932]\n",
      "[982, 3915]\n",
      "[13280, 2230]\n",
      "[13377, 1630]\n",
      "[4521, 2442]\n",
      "[28282, 30936]\n",
      "[1098, 9483]\n",
      "[1404, 3862]\n",
      "[8616, 1071]\n",
      "[8111, 1629]\n",
      "[1664, 13212]\n",
      "[26021, 30933]\n",
      "[28578, 30936]\n",
      "[4046, 1629]\n",
      "[24833, 30932]\n",
      "[1627, 1103]\n",
      "[2870, 1532]\n",
      "[23162, 1324]\n",
      "[1475, 9534]\n",
      "[18532, 1459]\n",
      "[11623, 1224]\n",
      "[15227, 1650]\n",
      "[982, 20847]\n",
      "[1411, 1077]\n",
      "[24418, 1142]\n",
      "[14675, 1743]\n",
      "[13923, 1066]\n",
      "[11724, 1630]\n",
      "[4873, 1093]\n",
      "[24743, 2767]\n",
      "[10907, 1441]\n",
      "[3107, 6007]\n",
      "[4934, 1255]\n",
      "[3129, 1441]\n",
      "[2914, 1095]\n",
      "[9743, 1406]\n",
      "[26216, 1476]\n",
      "[17026, 2288]\n",
      "[25850, 1441]\n",
      "[4979, 1228]\n",
      "[1334, 1180]\n",
      "[2891, 6602]\n",
      "[1574, 13879]\n",
      "[27383, 15508]\n",
      "[1620, 1361]\n",
      "[18554, 5213]\n",
      "[10616, 30938]\n",
      "[1292, 12825]\n",
      "[8654, 1280]\n",
      "[3783, 1462]\n",
      "[1884, 1284, 7166]\n",
      "[4806, 1006]\n",
      "[8222, 3726]\n",
      "[19466, 4940]\n",
      "[15694, 9995]\n",
      "[24691, 1095]\n",
      "[6231, 1071]\n",
      "[2007, 1169]\n",
      "[1985, 1806]\n",
      "[10233, 30933]\n",
      "[26962, 1024]\n",
      "[4034, 1485]\n",
      "[3275, 17023]\n",
      "[29429, 30950]\n",
      "[26994, 8767]\n",
      "[25481, 1101]\n",
      "[11130, 30148]\n",
      "[24234, 1081]\n",
      "[4436, 1806]\n",
      "[8969, 1025]\n",
      "[29080, 1280]\n",
      "[25998, 9871]\n",
      "[1237, 2230]\n",
      "[12537, 1160]\n",
      "[2157, 2136]\n",
      "[15083, 30932]\n",
      "[3553, 1542]\n",
      "[19773, 1071]\n",
      "[5577, 1288]\n",
      "[17323, 8724]\n",
      "[1825, 7163]\n",
      "[30215, 1120]\n",
      "[20543, 1160]\n",
      "[24871, 12356]\n",
      "[14081, 1889]\n",
      "[4684, 2525]\n",
      "[7988, 1047]\n",
      "[19526, 1071]\n",
      "[1395, 1558]\n",
      "[1825, 1213]\n",
      "[3312, 1188]\n",
      "[24253, 1121]\n",
      "[2051, 30932]\n",
      "[14313, 30932]\n",
      "[18727, 1239]\n",
      "[11967, 9483]\n",
      "[22268, 13794]\n",
      "[8047, 1630]\n",
      "[4979, 2561]\n",
      "[1250, 13879]\n",
      "[29040, 1071]\n",
      "[13054, 1076]\n",
      "[11382, 2025]\n",
      "[2222, 10177]\n",
      "[2222, 1811]\n",
      "[11618, 30933]\n",
      "[14148, 1462]\n",
      "[27771, 1239]\n",
      "[26087, 1123]\n",
      "[14301, 1806]\n",
      "[7392, 7166]\n",
      "[26652, 1066]\n",
      "[10949, 2010]\n",
      "[13584, 30932]\n",
      "[1967, 1558]\n",
      "[18531, 1295]\n",
      "[17106, 2623]\n",
      "[15935, 1179]\n",
      "[21498, 1123]\n",
      "[26212, 2246]\n",
      "[1967, 1592]\n",
      "[23265, 28509]\n",
      "[19189, 1093]\n",
      "[4995, 1647]\n",
      "[17094, 1586]\n",
      "[4936, 16111]\n",
      "[14864, 1532]\n",
      "[1883, 30932]\n",
      "[18133, 8067]\n",
      "[11109, 30936]\n",
      "[26642, 6685]\n",
      "[3509, 8230]\n",
      "[6265, 2532]\n",
      "[3423, 1876]\n",
      "[10149, 11156]\n",
      "[18873, 30936]\n",
      "[23774, 1035]\n",
      "[1975, 1071]\n",
      "[25069, 30938]\n",
      "[23470, 7166]\n",
      "[1715, 1093]\n",
      "[3864, 1239]\n",
      "[4203, 30933]\n",
      "[3509, 9603]\n",
      "[17389, 1024]\n",
      "[6542, 1066]\n",
      "[4997, 1093]\n",
      "[1664, 10211]\n",
      "[11579, 30939]\n",
      "[6806, 1188]\n",
      "[1345, 1194]\n",
      "[18684, 1024]\n",
      "[19985, 1772]\n",
      "[30062, 2634]\n",
      "[10412, 1006]\n",
      "[5642, 1048]\n",
      "[24117, 30932]\n",
      "[25542, 1071]\n",
      "[30725, 1228]\n",
      "[25666, 30933]\n",
      "[3267, 1154]\n",
      "[5540, 10790]\n",
      "[3048, 2630]\n",
      "[1061, 2623]\n",
      "[4056, 1288]\n",
      "[30330, 30936]\n",
      "[1434, 6427]\n",
      "[11689, 20324]\n",
      "[5032, 8294]\n",
      "[2405, 30933]\n",
      "[28362, 1898]\n",
      "[1928, 2702]\n",
      "[10503, 1047]\n",
      "[7204, 7166]\n",
      "[15365, 1402]\n",
      "[23953, 30932]\n",
      "[1157, 15038]\n",
      "[2046, 3266]\n",
      "[3666, 1806]\n",
      "[1607, 5931]\n",
      "[8832, 1481]\n",
      "[1950, 6804]\n",
      "[4476, 4543]\n",
      "[3564, 30936]\n",
      "[20848, 30936]\n",
      "[1822, 1532]\n",
      "[4395, 1469]\n",
      "[1211, 1558]\n",
      "[23571, 2100]\n",
      "[14148, 1478]\n",
      "[1395, 1280]\n",
      "[27071, 1280]\n",
      "[21755, 1586]\n",
      "[2605, 1160]\n",
      "[1524, 2154]\n",
      "[11976, 2003]\n",
      "[30079, 1558]\n",
      "[1073, 30933]\n",
      "[14706, 30936]\n",
      "[5384, 1188]\n",
      "[7985, 30936]\n",
      "[1240, 8230]\n",
      "[9432, 1629]\n",
      "[11132, 1485]\n",
      "[27303, 8230]\n",
      "[2973, 8230]\n",
      "[20889, 1441]\n",
      "[19294, 1188]\n",
      "[14241, 1629]\n",
      "[14988, 2230]\n",
      "[5356, 2230]\n",
      "[27413, 17537]\n",
      "[5183, 1123]\n",
      "[1661, 10703]\n",
      "[23044, 3345]\n",
      "[1523, 1138]\n",
      "[25193, 1120]\n",
      "[28159, 1420]\n",
      "[1554, 6804]\n",
      "[20687, 1485]\n",
      "[1096, 1050]\n",
      "[13831, 3726]\n",
      "[3152, 1032]\n",
      "[1051, 1288]\n",
      "[10776, 5129]\n",
      "[5406, 30933]\n",
      "[6752, 30932]\n",
      "[14716, 30933]\n",
      "[2891, 6541]\n",
      "[23333, 1277]\n",
      "[16514, 1180]\n",
      "[12907, 2052]\n",
      "[5016, 1093]\n",
      "[2611, 30932]\n",
      "[1365, 1095]\n",
      "[30616, 1743]\n",
      "[23496, 5582]\n",
      "[1354, 5057]\n",
      "[29816, 1160]\n",
      "[2915, 1093]\n",
      "[22395, 1101]\n",
      "[13925, 30932]\n",
      "[8104, 30933]\n",
      "[10438, 1066]\n",
      "[25214, 1430]\n",
      "[29547, 5021]\n",
      "[4150, 1088]\n",
      "[1890, 1532]\n",
      "[24914, 3533]\n",
      "[1334, 1123]\n",
      "[13156, 5021]\n",
      "[11164, 1743]\n",
      "[25832, 2872]\n",
      "[24513, 15305]\n",
      "[3290, 10703]\n",
      "[4812, 1558]\n",
      "[1114, 1050]\n",
      "[1582, 30932]\n",
      "[2157, 1301]\n",
      "[1697, 4115]\n",
      "[8367, 6879]\n",
      "[16734, 1239]\n",
      "[16210, 30936]\n",
      "[12521, 5655]\n",
      "[27630, 1485]\n",
      "[30722, 4076]\n",
      "[13456, 1517]\n",
      "[11048, 1562]\n",
      "[4219, 1270]\n",
      "[25963, 6064]\n",
      "[2775, 1270]\n",
      "[14205, 5655]\n",
      "[11394, 2634]\n",
      "[1601, 30932]\n",
      "[1217, 9995]\n",
      "[18020, 30932]\n",
      "[5333, 2230]\n",
      "[26507, 4544]\n",
      "[1079, 1758]\n",
      "[7240, 30932]\n",
      "[27804, 5638]\n",
      "[1132, 1194]\n",
      "[26173, 1630]\n",
      "[11311, 1558]\n",
      "[16737, 3473]\n",
      "[8522, 1629]\n",
      "[24484, 26018]\n",
      "[8096, 30932]\n",
      "[29746, 30935]\n",
      "[1933, 1047]\n",
      "[8518, 1188]\n",
      "[9643, 1169]\n",
      "[28005, 1228]\n",
      "[5112, 1154]\n",
      "[15926, 1629]\n",
      "[7959, 2230]\n",
      "[22450, 5027]\n",
      "[27224, 1220]\n",
      "[17896, 2960]\n",
      "[21990, 30148]\n",
      "[3444, 1133]\n",
      "[4240, 5167]\n",
      "[25394, 1071]\n",
      "[6076, 1532]\n",
      "[23378, 1485]\n",
      "[23672, 1630]\n",
      "[30864, 1093]\n",
      "[11110, 30932]\n",
      "[16761, 30933]\n",
      "[16584, 1436]\n",
      "[12407, 1629]\n",
      "[2432, 1180]\n",
      "[8072, 1441]\n",
      "[29707, 3110]\n",
      "[11674, 1095]\n",
      "[1080, 13841]\n",
      "[26870, 30933]\n",
      "[6581, 1138]\n",
      "[3040, 9871]\n",
      "[13554, 1405]\n",
      "[8940, 1469]\n",
      "[24482, 30936]\n",
      "[2483, 1629]\n",
      "[15791, 1898]\n",
      "[13359, 2564]\n",
      "[6959, 1193]\n",
      "[18405, 1138]\n",
      "[4072, 1938]\n",
      "[10510, 1956]\n",
      "[29850, 1323]\n",
      "[6673, 2634]\n",
      "[15236, 12013]\n",
      "[1795, 1629]\n",
      "[22501, 1361]\n",
      "[5130, 13794]\n",
      "[1548, 30983]\n",
      "[18548, 1277]\n",
      "[16407, 1047]\n",
      "[3075, 1441]\n",
      "[22911, 8997]\n",
      "[13820, 1047]\n",
      "[6706, 30933]\n",
      "[16718, 30933]\n",
      "[2688, 6007]\n",
      "[9743, 30933]\n",
      "[30514, 30936]\n",
      "[25996, 1558]\n",
      "[3817, 2942]\n",
      "[15018, 30932]\n",
      "[22197, 1188]\n",
      "[3312, 2942]\n",
      "[3913, 2942]\n",
      "[21119, 1121]\n",
      "[2928, 30721]\n",
      "[17744, 1095]\n",
      "[8427, 2585]\n",
      "[12649, 1081]\n",
      "[7169, 1482]\n",
      "[18243, 1120]\n",
      "[4893, 3883]\n",
      "[9202, 30936]\n",
      "[1905, 1647]\n",
      "[23387, 30936]\n",
      "[11870, 1138]\n",
      "[8185, 1052]\n",
      "[24894, 1460]\n",
      "[17542, 3809]\n",
      "[21318, 2442]\n",
      "[5384, 3489]\n",
      "[12470, 4076]\n",
      "[1498, 2159, 1160]\n",
      "[20473, 8257]\n",
      "[1334, 6007]\n",
      "[25991, 30933]\n",
      "[18356, 1441]\n",
      "[6032, 1323]\n",
      "[20603, 1047]\n",
      "[1345, 1095]\n",
      "[15504, 1193]\n",
      "[3854, 5217]\n",
      "[6231, 14204]\n",
      "[13406, 1629]\n",
      "[27642, 1024]\n",
      "[18705, 30932]\n",
      "[12244, 1193]\n",
      "[2362, 7231]\n",
      "[5807, 1277]\n",
      "[30722, 1459]\n",
      "[1170, 30932]\n",
      "[9765, 1402]\n",
      "[3993, 8230]\n",
      "[1498, 1066]\n",
      "[3074, 3581]\n",
      "[15111, 4507]\n",
      "[29093, 1413]\n",
      "[25858, 1277]\n",
      "[15088, 1629]\n",
      "[20730, 17984]\n",
      "[25286, 6879]\n",
      "[3178, 2623]\n",
      "[3178, 1050]\n",
      "[9099, 1485]\n",
      "[27557, 4076]\n",
      "[17549, 1420]\n",
      "[1218, 11346]\n",
      "[23175, 1103]\n",
      "[1678, 1121]\n",
      "[25515, 9603]\n",
      "[2242, 8230]\n",
      "[4560, 4543]\n",
      "[26413, 1485]\n",
      "[25353, 1095]\n",
      "[4560, 20115]\n",
      "[11612, 3438]\n",
      "[4164, 1647]\n",
      "[18531, 7231]\n",
      "[25283, 2230]\n",
      "[2110, 10790]\n",
      "[25189, 1270]\n",
      "[9461, 1420]\n",
      "[20920, 9433]\n",
      "[1620, 12165]\n",
      "[4770, 20681]\n",
      "[24644, 5431]\n",
      "[23355, 11138]\n",
      "[4602, 1558]\n",
      "[18745, 2010]\n",
      "[1526, 1066]\n",
      "[11819, 3227]\n",
      "[27333, 1324]\n",
      "[3165, 3726]\n",
      "[4043, 1095]\n",
      "[28405, 1413]\n",
      "[20519, 1123]\n",
      "[15755, 1323]\n",
      "[1550, 11571]\n",
      "[29424, 30933]\n",
      "[2027, 6612]\n",
      "[15370, 2656]\n",
      "[23237, 3883]\n",
      "[5896, 30936]\n",
      "[24827, 30933]\n",
      "[1434, 3883]\n",
      "[27108, 1558]\n",
      "[4567, 30933]\n",
      "[8773, 1032]\n",
      "[29402, 2442]\n",
      "[27468, 1562]\n",
      "[21509, 5115]\n",
      "[27195, 15508]\n",
      "[20124, 1630]\n",
      "[8594, 30933]\n",
      "[8594, 1485]\n",
      "[2870, 2028]\n",
      "[1080, 1647]\n",
      "[1959, 1277]\n",
      "[9635, 3473]\n",
      "[18359, 9433]\n",
      "[27071, 1138]\n",
      "[4851, 1103]\n",
      "[8028, 1188]\n",
      "[24528, 1071]\n",
      "[7556, 1460]\n",
      "[7437, 1160]\n",
      "[6738, 10667]\n",
      "[1933, 1088]\n",
      "[25429, 1629]\n",
      "[2505, 1228]\n",
      "[21969, 1485]\n",
      "[28620, 2789]\n",
      "[19593, 1093]\n",
      "[11928, 1485]\n",
      "[14459, 30932]\n",
      "[5535, 1047]\n",
      "[6290, 1047]\n",
      "[17442, 1160]\n",
      "[10094, 11982]\n",
      "[13864, 1071]\n",
      "[1200, 3400]\n",
      "[2383, 30938]\n",
      "[7170, 2560]\n",
      "[4000, 1629]\n",
      "[3067, 1093]\n",
      "[26843, 30936]\n",
      "[25545, 1361]\n",
      "[23611, 3873]\n",
      "[23451, 3533]\n",
      "[23416, 1629]\n",
      "[2414, 17208]\n",
      "[5804, 1123]\n",
      "[5643, 1647]\n",
      "[19849, 1629]\n",
      "[1550, 1280]\n",
      "[6304, 1095]\n",
      "[4331, 2532]\n",
      "[1427, 1562]\n",
      "[5173, 1130, 30931]\n",
      "[4352, 11047]\n",
      "[22354, 30936]\n",
      "[8107, 1024]\n",
      "[3844, 1629]\n",
      "[13081, 30933]\n",
      "[10094, 8230]\n",
      "[3775, 1889]\n",
      "[22956, 3581]\n",
      "[30810, 1532]\n",
      "[20388, 1048]\n",
      "[17623, 1180]\n",
      "[17127, 4903]\n",
      "[1848, 1562]\n",
      "[5493, 2630]\n",
      "[1687, 1517]\n",
      "[8275, 1154]\n",
      "[1443, 8997]\n",
      "[1848, 8230]\n",
      "[5540, 1071]\n",
      "[4317, 1478]\n",
      "[3305, 3726]\n",
      "[1483, 30939]\n",
      "[28013, 1228]\n",
      "[7556, 8742]\n",
      "[4594, 1048]\n",
      "[15965, 1629]\n",
      "[1857, 4747]\n",
      "[1434, 14808]\n",
      "[4297, 19351]\n",
      "[6299, 1095]\n",
      "[28961, 9760]\n",
      "[15992, 9819]\n",
      "[1528, 3533]\n",
      "[30578, 1476]\n",
      "[30913, 2230]\n",
      "[1434, 2942]\n",
      "[14914, 3533]\n",
      "[3818, 2122]\n",
      "[1114, 1239]\n",
      "[3913, 1088]\n",
      "[8161, 1270]\n",
      "[3268, 5027]\n",
      "[25780, 30936]\n",
      "[5719, 2230]\n",
      "[17339, 1710]\n",
      "[10298, 1160]\n",
      "[15844, 7327]\n",
      "[2217, 14321]\n",
      "[2251, 8997]\n",
      "[1073, 1558]\n",
      "[27136, 2293]\n",
      "[17281, 1081]\n",
      "[8557, 1066]\n",
      "[13277, 1441]\n",
      "[7045, 3493]\n",
      "[3503, 30936]\n",
      "[14041, 1193]\n",
      "[10062, 1120]\n",
      "[5121, 30948]\n",
      "[2110, 30934]\n",
      "[16147, 6685]\n",
      "[982, 3915, 16100, 30933]\n",
      "[28349, 1462]\n",
      "[30617, 11809]\n",
      "[6168, 2010]\n",
      "[16517, 4076]\n",
      "[11305, 30936]\n",
      "[6438, 1899]\n",
      "[5278, 1625]\n",
      "[7244, 1898]\n",
      "[28510, 1066]\n",
      "[27659, 1071]\n",
      "[7950, 1103]\n",
      "[6299, 1066]\n",
      "[4550, 1280]\n",
      "[1620, 30932]\n",
      "[6034, 1095]\n",
      "[16115, 1361]\n",
      "[17484, 15032]\n",
      "[25092, 1386]\n",
      "[22279, 1179]\n",
      "[18849, 1820]\n",
      "[11822, 1188]\n",
      "[19667, 3991]\n",
      "[3553, 2208]\n",
      "[17372, 1024]\n",
      "[7122, 3344]\n",
      "[8152, 3726]\n",
      "[1715, 1180]\n",
      "[19297, 30936]\n",
      "[6335, 1629]\n",
      "[9206, 1441]\n",
      "[27619, 1180]\n",
      "[22972, 6722]\n",
      "[5410, 30940]\n",
      "[5952, 3146]\n",
      "[1110, 1323]\n",
      "[11460, 1050]\n",
      "[18354, 4076]\n",
      "[7376, 6007]\n",
      "[7385, 1290]\n",
      "[25171, 1629]\n",
      "[5121, 2025]\n",
      "[13918, 1743]\n",
      "[22231, 1288]\n",
      "[27105, 1899]\n",
      "[28971, 1629]\n",
      "[7914, 6745]\n",
      "[7500, 3438]\n",
      "[2166, 1047]\n",
      "[3917, 1629]\n",
      "[26411, 1485]\n",
      "[2688, 1120]\n",
      "[3631, 1746]\n",
      "[11304, 1120]\n",
      "[21044, 1441]\n",
      "[1933, 30932]\n",
      "[5774, 1095]\n",
      "[1235, 1592]\n",
      "[1804, 3991]\n",
      "[1823, 1402]\n",
      "[8047, 30932]\n",
      "[25743, 5788]\n",
      "[21144, 1103]\n",
      "[5054, 1562]\n",
      "[10029, 1193]\n",
      "[2007, 1093]\n",
      "[4560, 1193]\n",
      "[1768, 8485]\n"
     ]
    }
   ],
   "source": [
    "# Path to grab dataframes containing nouns from the AnCora Tree Banks\n",
    "datapath = 'datasets/'\n",
    "\n",
    "# This line generates 3 dictionaries with hand-annotated noun:article pairs\n",
    "# dct_noun_singletok\n",
    "# dct_noun_multitok_morph\n",
    "# dct_noun_multitok_nonmorph\n",
    "%run -i 'create_annotated_dicts.py'\n",
    "\n",
    "### Load the datasets one by one\n",
    "\n",
    "# For default SINGLE-TOKEN plurals\n",
    "filename = 'nounlist_single-token-plurals.csv'\n",
    "df_noun = pd.read_csv(os.path.join(datapath,filename))\n",
    "dct_noun = dct_noun_singletok\n",
    "df_singletok = make_sentences_df(dct_noun,df_noun)\n",
    "\n",
    "print('original list len:',df_noun.shape[0],'select list len:', len(dct_noun))\n",
    "\n",
    "data_source = 'single-token' \n",
    "probs_df_singletok,_ = get_article_predictions(df_singletok,data_source)\n",
    "\n",
    "\n",
    "# For default MULTI-TOKEN, MORPHEMIC plurals\n",
    "filename = 'nounlist_multi-token-morph-plurals.csv'\n",
    "df_noun = pd.read_csv(os.path.join(datapath,filename))\n",
    "dct_noun = dct_noun_multitok_morph\n",
    "df_multitok_morph = make_sentences_df(dct_noun,df_noun)\n",
    "\n",
    "print('original list len:',df_noun.shape[0],'select list len:', len(dct_noun))\n",
    "\n",
    "data_source = 'morphemic' \n",
    "probs_df_multitok_morph,_ = get_article_predictions(df_multitok_morph,data_source)\n",
    "\n",
    "\n",
    "# For default MULTI-TOKEN, NONMORPHEMIC plurals\n",
    "filename = 'nounlist_multi-token-nonmorph-plurals.csv'\n",
    "df_noun = pd.read_csv(os.path.join(datapath,filename))\n",
    "dct_noun = dct_noun_multitok_nonmorph\n",
    "df_multitok_nonmorph = make_sentences_df(dct_noun,df_noun)\n",
    "\n",
    "print('original list len:',df_noun.shape[0],'select list len:', len(dct_noun))\n",
    "\n",
    "data_source = 'non_morphemic' \n",
    "probs_df_multitok_nonmorph,_ = get_article_predictions(df_multitok_nonmorph,data_source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a2a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df_singletok['surprisal'] = probs_df_singletok['verb_probs'].apply(lambda x: -np.log(x))\n",
    "probs_df_multitok_morph['surprisal'] = probs_df_multitok_morph['verb_probs'].apply(lambda x: -np.log(x))\n",
    "probs_df_multitok_nonmorph['surprisal'] = probs_df_multitok_nonmorph['verb_probs'].apply(lambda x: -np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737fa84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "### Pause to check that the default tokenizations for plurals are, in fact, morphemic when you expect them to be\n",
    "\n",
    "non_morphemic_list = []\n",
    "for (_,row) in df_multitok_morph.iterrows(): \n",
    "    \n",
    "    sing = row['lemma']\n",
    "    plur = row['word_form']\n",
    "    affix = row['affix']\n",
    "    mod_affix = \"##\" + affix\n",
    "    \n",
    "    sing_tokids = tokenizer.encode(sing,add_special_tokens=False)\n",
    "    \n",
    "    if row['tokenization_type'] == 'artificial': \n",
    "        plur_tokids = tokenizer.encode([sing]+[mod_affix],add_special_tokens=False)\n",
    "        \n",
    "    elif row['tokenization_type'] == 'default': \n",
    "        plur_tokids = tokenizer.encode(plur,add_special_tokens=False)\n",
    "\n",
    "\n",
    "    affix_tokid = tokenizer.encode([mod_affix],add_special_tokens=False)[0]\n",
    "\n",
    "    n_plural_tokens = len(plur_tokids)\n",
    "    \n",
    "    sing_tokens = tokenizer.convert_ids_to_tokens(sing_tokids)\n",
    "    plural_tokens = tokenizer.convert_ids_to_tokens(plur_tokids)\n",
    "    \n",
    "    if n_plural_tokens == 1:\n",
    "        check_morph = \"singular single\"\n",
    "        \n",
    "    elif affix_tokid in plur_tokids:\n",
    "        check_morph = \"morphemic\"\n",
    "\n",
    "    ### Multi-token, non-morphemic\n",
    "    else:\n",
    "        check_morph = \"non_morphemic\"\n",
    "\n",
    "        print(sing,plural_tokens,check_morph)\n",
    "        \n",
    "        non_morphemic_list.append(sing)\n",
    "\n",
    "print(non_morphemic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0544c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "### Pause to check that the default tokenizations for plurals are, in fact, nonmorphemic when you expect them to be\n",
    "\n",
    "morphemic_list = []\n",
    "for (_,row) in df_multitok_nonmorph.iterrows(): \n",
    "    \n",
    "    sing = row['lemma']\n",
    "    plur = row['word_form']\n",
    "    affix = row['affix']\n",
    "    mod_affix = \"##\" + affix\n",
    "    \n",
    "    sing_tokids = tokenizer.encode(sing,add_special_tokens=False)\n",
    "    \n",
    "    if row['tokenization_type'] == 'artificial': \n",
    "        plur_tokids = tokenizer.encode([sing]+[mod_affix],add_special_tokens=False)\n",
    "        \n",
    "    elif row['tokenization_type'] == 'default': \n",
    "        plur_tokids = tokenizer.encode(plur,add_special_tokens=False)\n",
    "\n",
    "\n",
    "    affix_tokid = tokenizer.encode([mod_affix],add_special_tokens=False)[0]\n",
    "\n",
    "    n_plural_tokens = len(plur_tokids)\n",
    "    \n",
    "    sing_tokens = tokenizer.convert_ids_to_tokens(sing_tokids)\n",
    "    plural_tokens = tokenizer.convert_ids_to_tokens(plur_tokids)\n",
    "    \n",
    "    if n_plural_tokens == 1:\n",
    "        check_morph = \"singular single\"\n",
    "        \n",
    "    elif (affix_tokid in plur_tokids) & (row['tokenization_type']=='default'):\n",
    "        check_morph = \"morphemic\"\n",
    "        \n",
    "        morphemic_list.append(sing)\n",
    "        print(sing,plural_tokens,check_morph)\n",
    "\n",
    "\n",
    "    ### Multi-token, non-morphemic\n",
    "    else:\n",
    "        check_morph = \"non_morphemic\"\n",
    "        \n",
    "print(morphemic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c9dfb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save each of these to a dataframe!\n",
    "\n",
    "savepath = 'results_unmasked_verb-agreement/'\n",
    "\n",
    "# if ~os.path.exists(savepath): \n",
    "os.mkdir(savepath)\n",
    "    \n",
    "\n",
    "probs_df_singletok.to_csv(os.path.join(savepath,'results_singletok.csv'))\n",
    "probs_df_multitok_morph.to_csv(os.path.join(savepath,'results_multitok_morph.csv'))\n",
    "probs_df_multitok_nonmorph.to_csv(os.path.join(savepath,'results_multitok_nonmorph.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548544e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
